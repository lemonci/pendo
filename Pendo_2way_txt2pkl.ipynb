{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINT = 'POINT'\n",
    "STROKE = 'STROKE'\n",
    "CHARACTER = 'CHARACTER'\n",
    "SAMPLE = 'SAMPLE'\n",
    "SIF = 'Serial_in_File'\n",
    "PATH = '' #'C:/Users/mengqili/Documents/txt_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Zero: Route choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Communicate upwards:\n",
    " * Get: start and end filenumber\n",
    " * Send: saved file with one file each number\n",
    "\n",
    "* Communicate downwards: \n",
    " * Object: choose the correct function \n",
    " * Send: full strings and filenumber\n",
    " * Get: dataframe (with filenumber inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pendoanalysis(start, end):\n",
    "    # set the file scope\n",
    "    for i in range(start,end):\n",
    "        if os.path.isfile(PATH +str(i)+'.txt'):\n",
    "            \n",
    "            # open the file\n",
    "            file = open(PATH + str(i)+'.txt','r') \n",
    "            \n",
    "            # get the string\n",
    "            pendodata = file.read() \n",
    "            \n",
    "            # then close the file\n",
    "            file.close() \n",
    "            \n",
    "            if len(pendodata) < 10:\n",
    "                print ('file error')\n",
    "            \n",
    "            if len(re.findall(r'\\[\\[\\[\\[',pendodata)) == 4: # check whether there are FOUR '[[[[' in the string\n",
    "                dfraw = stringprocessA(pendodata, i) # There are FOUR '[[[[' in the string, go A route\n",
    "            else:\n",
    "                dfraw = stringprocessB(pendodata, i)# There aren't FOUR '[[[[' in the string, go B route\n",
    "            \n",
    "            if len(dfraw) == 1:\n",
    "                print ('Validation failed')\n",
    "            else:\n",
    "            \n",
    "                # save the DataFrame\n",
    "                savedf(dfraw,i)    # Save the dataframe\n",
    "                print (str(i)+' has been processed')\n",
    "            \n",
    "        else:\n",
    "            print ('Sample number '+str(i) + ' does NOT exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the DataFrame and save it into a pkl file\n",
    "\n",
    "def savedf(df,filenumber):\n",
    "    \n",
    "    if len(df.columns)  == 8:\n",
    "        # set new columns' names: with SIF\n",
    "        df.columns = ['X', 'Y', 'Z', POINT, STROKE, CHARACTER, SIF, SAMPLE]\n",
    "        #Adjust sequence of columns before save to pickles\n",
    "        df[[SAMPLE, CHARACTER, STROKE, POINT,'X', 'Y', 'Z', SIF]].to_pickle(str(filenumber)+\".pkl\")\n",
    "        #to_hdf(str(filenumber)+'.h5', key='df', mode='w')\n",
    "\n",
    "    elif len(df.columns) == 7 :\n",
    "        # set new columns' names: without SIF\n",
    "        df.columns = ['X', 'Y', 'Z', POINT, STROKE, CHARACTER, SAMPLE]\n",
    "        #Adjust sequence of columns before save to pickles\n",
    "        df = df[[SAMPLE, CHARACTER, STROKE, POINT,'X', 'Y', 'Z']].to_pickle(str(filenumber)+\".pkl\")\n",
    "\n",
    "    else:\n",
    "        print ('df columns are not 7 or 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1 functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Communicate upwards:\n",
    " * Get: full string\n",
    " * Send: dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1: Character number Not in Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Communicate downwards: \n",
    " * Object: the charactorprocessing function of the route\n",
    " * Send: \n",
    " * Get: dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receive the string for one sample and the serial number of the sample;\n",
    "# split the sample into strings of characters and use FUNCTION characterprocess to process each character\n",
    "# return a dataframe for the sample\n",
    "def stringprocessA(fullstring, filenumber):\n",
    "    \n",
    "    print ('Processing '+str(filenumber)+' in Route A')\n",
    "        \n",
    "    \n",
    "    charlist = re.findall(r'\\[(\\[\\[.+?\\]\\])\\]',\n",
    "                re.findall(r'\\[(\\[\\[\\[.+?\\]\\]\\])\\]',fullstring)[0]\n",
    "                )\n",
    "    # search for '[[[[ * ]]]]' and return the first matching string without the outer [] \n",
    "    # then search for '[[[*]]]' and return a list of strings for each character\n",
    "    \n",
    "    \n",
    "    dflist = []\n",
    "    for char in charlist:\n",
    "        dflist.append(characterprocess(char))\n",
    "    # Assign the serial of character by the sequence in the list\n",
    "    counter = 0\n",
    "    for singledf in dflist:\n",
    "        singledf[CHARACTER] = counter\n",
    "        counter+=1\n",
    "\n",
    "    returndf = pd.concat(dflist)  \n",
    "\n",
    "    # build a new column to store the sample number\n",
    "    returndf[SAMPLE] = filenumber\n",
    "\n",
    "    # validate the process\n",
    "    if validation(fullstring, dflist) == 1:\n",
    "        return returndf\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2 : Character number in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed \n",
    "# Changed RE to get character string instead of sample string\n",
    "# should have 180 characters, only use the first 90 characters.\n",
    "\n",
    "# Numberofpools controls how many threads shall be used simultaneously\n",
    "\n",
    "def stringprocessB(fullstring ,filenumber):\n",
    "    \n",
    "    print ('Processing '+str(filenumber)+' in Route B')\n",
    "    \n",
    "    pendodata = re.findall(r\"\"\"(&quot;[0-9]+&quot;:\\[\\[\\[.+?\\]\\]\\])\"\"\",re.split('&quot;virtual&quot',fullstring)[0])\n",
    "    \n",
    "    dflist = []\n",
    "    for da in pendodata:\n",
    "        dflist.append(characterprocess(da))\n",
    "\n",
    "    # set serial in the file to record the sequence in the html file\n",
    "#    for i in range(90):\n",
    "#        dflist[i][SIF] = i\n",
    "\n",
    "    # the previous code will produce error when there is less than 90 characters,\n",
    "    # Therefore, change the way to iterate the dflist\n",
    "    counter = 0\n",
    "    for singledf in dflist:\n",
    "        print(singledf)\n",
    "        singledf[SIF] = counter\n",
    "        counter+=1\n",
    "\n",
    "    # Concatenate all DataFrames and sort by the serial of character instead of the sequence in the html file \n",
    "    returndf = pd.concat(dflist).sort_values(by=[CHARACTER])\n",
    "    \n",
    "    # build a new column to store the sample number\n",
    "    returndf[SAMPLE] = filenumber\n",
    "    \n",
    "    # validate the process\n",
    "    if validation(fullstring, dflist) == 1:\n",
    "        return returndf\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Changed input: \n",
    "# no longer need serial input; get serial from re.findall instead\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# receive the string for one character;\n",
    "# split the character into strings of strokes and use FUNCTION strokeprocess to process each stroke\n",
    "# if there is a serial number in the string record it in the dataframe, if not do nothing;\n",
    "# return a dataframe for the charactor\n",
    "\n",
    "def characterprocess(characterstr):\n",
    "    #normal process\n",
    "    i = 0\n",
    "    characterdata = pd.DataFrame(columns = [0,1,2,POINT,STROKE])\n",
    "    for singlestroke in re.findall(r'\\[(\\[\\d.+?\\])\\]',characterstr):\n",
    "        characterdata = pd.concat([characterdata,strokeprocess(singlestroke,i)])\n",
    "        i+=1\n",
    "    \n",
    "    # Check whether the input contains a serial\n",
    "    \n",
    "    if re.findall(r'&quot;(.+)&quot;:',characterstr):\n",
    "        \n",
    "        # if the search does not returns a NONE, the string contains a serial number of character\n",
    "        characterdata[CHARACTER] = int(re.findall(r'&quot;(.+)&quot;:',characterstr)[0]) \n",
    "        \n",
    "        #else the search returns a NONE, no process shall be performed,         \n",
    "        #and the character serial shall be assigned later, in the FUNCTION stringprocess \n",
    "    return characterdata\n",
    "\n",
    "##################################################################################################\n",
    "# receive the string for one stroke and the serial number of the stroke;\n",
    "# split the stroke into strings of points and use FUNCTION pointprocess to process each point\n",
    "# return a dataframe for the stroke\n",
    "def strokeprocess(strokestr, strokenumber):\n",
    "    i = 0\n",
    "    strokedata = pd.DataFrame(columns = [0,1,2,POINT])\n",
    "    for singlepoint in re.findall(r'\\[(.+?)\\]',strokestr):\n",
    "        strokedata = pd.concat([strokedata,pointprocess(singlepoint,i)])\n",
    "        i+=1\n",
    "    strokedata[STROKE] = strokenumber\n",
    "    return strokedata\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "# receive the string for one point and the serial number of the point;\n",
    "# return a dataframe for the point\n",
    "\n",
    "def pointprocess(pointstr, pointnumber):\n",
    "    pointdata = pd.DataFrame(pd.to_numeric(re.split(',',pointstr))).T\n",
    "    pointdata[POINT] = pointnumber\n",
    "    return pointdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether the first number in returning df is the same as the first number in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "\n",
    "def validation(fullstring, dflist): \n",
    "    #test in case not find the first three numbers.\n",
    "    firstpoint = re.findall(r\"\"\"\\[(\\d.+?)\\]\"\"\",fullstring)[0]\n",
    "    \n",
    "    if int(re.split(',',firstpoint)[0]) == dflist[0].iloc[0,0]:\n",
    "        #return the final DataFrame when the first element of the list is correct\n",
    "        return 1\n",
    "    else:\n",
    "        #print error message when the list is incorrect\n",
    "        return 0 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Use the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first argument is start number\n",
    "# the second argument is end number\n",
    "# the third argument is how many character shall be processed simultaneously. \n",
    "\n",
    "pendoanalysis(109,110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_hdf('2.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('109.pkl')\n",
    "Char13 = df[df.CHARACTER == 13]\n",
    "Stroke5 = Char13[Char13.STROKE == 5]\n",
    "Stroke5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
